Результаты проекта:

1) В ходе проекта был проведен анализ результатов А/В теста новой механики оплаты по 3-м метрикам (CR, ARPU, ARPPU). Было выявлено статистически значимое улучшение ARPPU (на 322 у.е.) и стат. не значимое ухудшение CR (- 0.4 п.п.).

В итоге: я рекомендовал выкатывать новую механику оплаты на всех пользователей.
2) Также, в ходе проекта, мной был реализован сложный SQL запрос с помощью библиотеки Pandahouse.
3) Была написана функция, которая автоматизирует процесс А/В теста с добавлением новых пользователей в группы (результат теста не изменился, метрика ARPPU также стат. значимо выросла).

Project results:

1) During the project, the results of A/B testing of the new payment mechanics were analyzed using 3 metrics (CR, ARPU, ARPU). A statistically significant improvement in ARPPU (by 322 cu) and stat. not a significant deterioration in CR (- 0.4 pp).

As a result: I recommended rolling out a new payment mechanics for all users.
2) Also, during the project, I implemented a complex SQL query using the Pandahouse library.
3) A function was written that automates the A/B test process with the addition of new users to groups (the test result has not changed, the ARPPU metric is also has stat. grown significantly).





Никита, приветствую!

У нас автоматическая проверка стиля кода; чтобы посмотреть на список ошибок, нужно

перейти во вкладку Pipelines под названием merge request
найти во второй колонке таблицы подчёркнутую строку вида "#1754" (число будет другое), под которым написано latest, и нажать на это число
найти на странице красный крест, справа от которого написано test, а ещё правее значок обновления; нажать на слово test
найти фразу "nbqa flake8 --ingore=...", выделенную зелёным цветом; она должна быть на 95 строке
всё, что ниже -- список ошибок в стиле кода.
Мои замечания и вопросы, выделенные полужирным шрифтом, если они будут, обязательно потребуют какой-то твоей реакции — ответов, исправлений, по ситуации, если хочешь, чтобы проект был зачтен. Остальные будут либо просто советами/рекомендациями, либо полезным, на мой взгляд, фидбеком; отвечать на них необязательно, но если захочешь что-то спросить или поспорить — пиши прямо здесь, в комментариях, я обязательно отвечу :)

Задание 1:

Среди заплативших есть те, кто не заходил на платформу во время эксперимента. Они не попали в твой итоговый датафрейм (после фильтрации в ячейке 31), и может быть это и правильно, а может и нет. В описании задания нет никаких подробностей, так что ты имел право действовать на свое усмотрение, но заметить такой артефакт на этапе предварительного знакомства с данными и как-то его осмыслить все-таки надо было. Аналитик такие вещи должен отлавливать. Представь, что это результат какой-то серьезной технической ошибки, которая ломает нам весь эксперимент и делает его бессмысленным, а мы этого не увидели…

По поводу условий применимости теста Стьюдента ты, на мой взгляд, делаешь слишком сильные утверждения. В общем и целом ты, может быть, прав. Но надо понимать, что все это основано на предельных теоремах (ЦПТ, и не только), которые называются предельными, потому что толкуют о пределах — о том, что происходит «в бесконечности», при n→inf. То есть что-то там в пределе сходится к нормальному распределению, но с какой скоростью сходится, мы не знаем — это очень сильно зависит от распределения ген.совокупности. Где-то достаточно n>10, а где-то и 10000 будет мало, и проверять такие вещи довольно сложно. Просто учти для себя на будущее.

В продолжение этой темы: в ячейке 54 ты сравниваешь ARPU. Эти распределения очень сильно перекошены влево, огромное количество нулей — у меня есть сомнения, что t-тест тут работает адекватно. Я бы посоветовал пройтись бутстрапом и сравнить результаты. Только очень тебя прошу, если будешь делать, не надо копипастить функцию бутстрапа с лекций, напиши ее сам, это совсем не сложно, если конечно понимаешь, как этот метод работает.

Ты пишешь: ...но не уверен, что конверсию можно проверить на нормальность Проверять можно что угодно, но вот если случайная величина может принимать только значения 0 и 1, она просто по определению нормальной быть не может, конечно. В силу ЦПТ (ну или ее частного случая для бинарных случаев— теоремы Муавра-Лапласа), выборочное среднее (т. е. доля единиц, или, если угодно, конверсия) может иметь тенденцию к норм.рапр. Но ведь это немного разные вещи.

Множественные сравнения — серьезная проблема, и очень здорово, что ты обратил на нее внимание и принял меры. +++ Не надо только забывать, что ошибка первого рода — это не что-то абстрактное, а это собственно ошибка, и если она случится, будут последствия. Поэтому вероятность ошибки должна как-то отражать тяжесть этих последствий. Представь, что новая фича не работает (или даже вредит), а мы ее раскатили. Что тогда будет? Ну или наоборот: она полезна, а мы ее забраковали — что тогда? Какая из этих двух ошибок принесет больше потерь бизнесу? Я все это к тому, что при выборе уровня значимости и мощности (не важно, с поправкой или нет) нужно всегда исходить из конкретного контекста конкретной задачи, а не полагаться на пресловутое 0,05, «потому что все так делают». Понятно, что это легче сказать, чем сделать (очень сложно, если вообще возможно, точно рассчитать последствия ошибок), но хороший аналитик все-таки старается исходить от задачи, а не от best practice. Никогда об этом не забывай.

Я не совсем понял, как ты провел ttest. Похоже, что это pingouin, но я не вижу импорта from pingouin import ttest. Потому что иначе у тебя должно быть pg.ttest, разве нет? UPD заметил твой комментарий в мердже уже после. Но все равно надо поправить, так оставлять нехорошо.

В выводах ты написал: При этом мощность т-теста по ARPPU ~ 0.87, что говорит о высокой вероятности получения ошибки 2 рода. Как раз наоборот. Вероятность такой ошибки = 1-0,87=0,13. Кстати, мощность зависит от уровня значимости. А ты уверен, что пингвин при этом учитывал поправку, которую ты делал выше? Я пингвином не пользуюсь, а из доки так и не понял, какую альфу он берет. Подозреваю, что все ту же старую добрую 0,05. По крайней мере CI он по умолчанию вычисляет 95%. С этим надо разобраться.

Задание 2 (SQL):

ОК.
Задание 3:

Здесь тоже хорошо. Замечу, что к функциям очень полезно всегда писать описание докстрингом сразу после def, это очень полезная привычка и правило хорошего тона в питоне. Это описание потом можно выводить с помощью имя_функции.__ doc __
Подведем итог: хорошая работа, если не считать нескольких спорных утверждений и незначительных помарок (кроме выделенного полужирным шрифтом, конечно). Жду исправлений и твоих комментариев/вопросов, если они будут.
Олег Цыбиков @o-tsybikov added 
corrections_expected
 label 1 week ago
Nikita Korotkov
Nikita Korotkov @n-korotkov · 1 week ago
Author
Developer




Олег, привет! Спасибо за обратную связь и комментарии, сделаю исправления в стилистике кода и исправлю все неточности (постараюсь сегодня, но, вероятно, до понедельника). Также добавлю новый коммент.

Хотел бы добавить ряд уточнений по поводу замечаний (по очередности комментариев):

Я как раз заметил такой артефакт (возможно просто не расписал), по этой причине я и оставил только тех, кто заходил на платформу во время эксперимента. Мы же тестировали новую платежную систему (или как-то так). Люди, которые не заходили на платформу просто не могли ее увидеть, поэтому нет смысла оставлять их в нашем эксперименте. Конечно это могло быть следствием ошибки нашей системы или чего-либо еще, но тут можно сгенерить очень много гипотез. Моя заключалась в том, что это просто люди, которые вошли в группы, но за период эксперимента не пользовались сервисом.

Обязательно учту, спасибо))

Согласен с твоей идеей, попробую реализовать бутстрап вместо т-теста. Вопрос: а если мы делаем т-тест в перемешку с бутстрапом, то как тут корректировать уровень альфа? как обычно?

Очень ценное замечание, спасибо, учту на будущее!

Спасибо! А что можно почитать, чтобы более детально понимать, в каких случаях уровень альфа нужно корректировать?

Да, верно, случайно запушил такой вариант, поправлю.

Не уверен по поводу уровня значимости, но вроде его там можно скорректировать. Попробую поправить. По поводу мощности, эта тема на курсе раскрывалась не очень обширно, поэтому не совсем пока что понимаю логику ее расчета. Можешь тоже поделиться каким-нибудь ресурсом?

Спасибо!
Nikita Korotkov @n-korotkov added 1 commit 1 week ago
95dcba1a - With corrections My awesome work on the final project/variant2, 17.01.2022
Compare with previous version
Nikita Korotkov @n-korotkov added 
done
 label 1 week ago
Nikita Korotkov @n-korotkov removed 
done
 label 1 week ago
Nikita Korotkov @n-korotkov added 
added_corrections
 label 1 week ago
Nikita Korotkov @n-korotkov approved this merge request 1 week ago
Nikita Korotkov
Nikita Korotkov @n-korotkov · 1 week ago
Author
Developer





Олег, привет! Доделал работу с учетом замечаний:

Добавил необходимые библиотеки;
Сделал дополнительно бутстрап по ARPU + скорректировал p-value на еще одно попарное сравнение (прости, но за основу для функции я взял ту, что была в лекции, однако это не умаляет того, что я знаю, как работает этот метод :) ) Надеюсь, ты подобный формат и имел ввиду. Если нет, дай знать.
Добавил докстринги, описывающие функции;
Я использовал немного другой метод из библиотеки пингвин + заметил, что мой вариант делал т-тест Уэлча, хотя дисперсии в данных гомогенны. Это тоже поправил;
Другой, выбранный мной, метод не рассчитывает мощность теста, что в данном случае хорошо, тк в рамках курса этот вопрос раскрывался слабо (по моему вообще не раскрывался), и я просто не совсем понимаю, как именно ее правильно измерить. Мой ментор мне как то говорил, что для этого необходимо провести А/А тест, но я не уверен.
Поэтому, если ты не против, я уберу эту часть исследования из моей работы, тк мощность рассчитывалась без корректировки на новый уровень альфа.

Если есть еще комментарии, дай знать. :)

Collapse replies
Олег Цыбиков
Олег Цыбиков @o-tsybikov · 3 days ago
Developer


Никита, приветствую еще раз!

Так, с бутстрепом у меня к тебе возникли серьезные вопросы. Твоя функция bootstrap делает вот такую штуку: statistic(sample_A - sample_B, q=0.99):

а потом, когда сравниваешь ARPU, ты в качестве statistic используешь quantile. Но ARPU - это среднее значение чека (average revenue per user - средний чек юзера). Именно средний. Я не прослеживаю связи между 99%-квантилем и средним.

ты проверяешь гипотезу, что два параметра (обозначим их x и y) равны, x = y, или по-другому говоря, x - y = 0. Разность двух параметров, а не параметр от разности.

И еще: посмотри на гистограмму в ячейке 55. Это распределение, мягко говоря, не похоже на нормальное, а твой бутстреп для расчета доверительного интервала использует norm.cdf. Это как же понимать?

Опционально еще вопрос: зачем происходит выравнивание размеров выборок в max([len(a_data), len(b_data)])?

Я ведь тебя честно предупреждал насчет бутстрепа =)

Большая просьба, когда будешь отвечать/исправлять, тэгни меня обязательно.


Resolve thread

Nikita Korotkov @n-korotkov added 1 commit 3 days ago
302e5ca9 - additional corrections
Compare with previous version
Nikita Korotkov @n-korotkov added 1 commit 3 days ago
507dfca3 - additional corrections
Compare with previous version
Nikita Korotkov
Nikita Korotkov @n-korotkov · 3 days ago
Author
Developer





Олег, привет! Заметил, что тест не пропустил снова стиль кода, немного подправил, но остались 2 ошибки, с которыми не пойму как поступить:

nikita_korotkov_17.01_n-korotkov_variant2.ipynb:cell_2:21:5: E722 do not use bare 'except' 116 except: 117 ^ 118nikita_korotkov_17.01_n-korotkov_variant2.ipynb:cell_64:17:9: F841 local variable 'active_users' is assigned to but never used 119 active_users = read_ya(active).rename(columns={'student_id': 'id'})

В первом случае, как я понимаю, нужно обозвать except, но не могу понять логику, что именно он от меня просит. Во втором - эта переменная может не использоваться, в зависимости от того как работает функция.

Заранее спасибо за совет! :)

Collapse replies
Олег Цыбиков
Олег Цыбиков @o-tsybikov · 3 days ago
Developer


В первом случае с try-except он недоволен, что ты используешь except без указания конкретного исключения, как бы в "голом" виде (https://www.flake8rules.com/rules/E722.html) - обычно лучше этого избегать. Но не так критично, просто возьми на заметку.

Второе также можешь игнорировать.


Resolve thread

Nikita Korotkov @n-korotkov added 1 commit 1 day ago
6b4bfa95 - coorections after second feedback
Compare with previous version
Nikita Korotkov @n-korotkov added 1 commit 1 day ago
d2c9d5f7 - coorections after second feedback
Compare with previous version
Nikita Korotkov
Nikita Korotkov @n-korotkov · 1 day ago
Author
Developer





@o-tsybikov , привет!

Спасибо за коммент) Как круто, что такие вещи всплывают, есть возможность лучше понять тему. Поэтому наоборот хорошо, что мы сейчас проделаем это упражнение, а не потом, когда это выльется в рамках бизнес-задач. =)

Однако я считаю очень странным, что на курсе нам преподают материал и предлагают функции, которые заведомо имеют в себе неточности и/или ошибки.

По поводу квантиля - настолько очевидная вещь (даже стыдно), но, видимо, из-за того, что я спешил, допустил такую дебильную ошибку. Конечно же ARPU - это среднее, поэтому поменял статистику на np.mean().
По поводу того, что мы сравниваем разницу параметров, уловил, то есть мы сравниваем разницу средних наших групп. Исправил этот момент в функции.
Немного не понял коммент про norm.cdf, мы же применяем этот метод не к изначальным ненормальным распределениям, а уже к распределению разницы средних наших бутстрапированных выборок, чтобы рассчитать уже его доверительный интервал. И это распределение примет нормальный или около-нормальный вид.
Касательно последнего опционального вопроса, предполагаю, что это сделано для того, чтобы нормировать данные на одинаковое количество наблюдений + предполагаю, это позволяет нам не ухудшать мощность теста из за разницы объема выборок. Но вот этот вопрос я пока просто взял на веру. Если сможешь направить, буду признателен.
Также переделал визуализацию через Plotly, визуально он мне больше нравится =).
Edited by Nikita Korotkov 1 day ago

Collapse replies
Олег Цыбиков
Олег Цыбиков @o-tsybikov · 46 minutes ago
Developer


Никита, и еще раз добрый вечер!

Я принимаю проект, все самые важные моменты мы с тобой обсудили и, я надеюсь, ясности теперь стало побольше.

Напоследок отвечу на твои последние комментарии.

в функции get_bootstrap из лекций не то чтобы ошибки. Например в случае со средним (mean) разность средних равна средней разности (с медианами это не так). А самое главное - в ней используются кое-какие чуть более продвинутые, хотя и несколько спорные, идеи, про которые вам на лекциях не рассказывали. Вообще, проверка гипотез с помощью бутстрепа это довольно неоднозначная тема. Вам эту функцию дали просто в качестве черного ящика, чтобы облегчить жизнь. А я задавал тебе вопросы только по тем моментам, которые ты, на мой взгляд, мог и должен был понимать.

про norm.cdf: если бы распределение было действительно похоже на нормальное, у меня бы вопросов не возникло, потому что все логично. Но я отчетливо помню, что там на гистограмме было что-то ужасное и совсем не нормальное. Такое часто случается, когда смотрим не на средние, а на медианы или что-то еще.

про выравнивание: верно, я тоже предполагаю, что это делается, чтобы не пострадала мощность. Но в классическом обычном бутстрепе выборки сэмплируются в том размере, в каком они есть изначально, в противном случае мы, как мне кажется, необоснованно занижаем/завышаем дисперсию того же среднего.

Если я что-то забыл, напиши. Но официальная часть на этом завершена. Проект принят. Желаю тебе успехов в дальнейшем.

Done
Nikita Korotkov
Nikita Korotkov @n-korotkov · just now
Author
Developer



@o-tsybikov

Олег, еще раз привет! Спасибо большое за твое время и за крайне ценные советы и комментарии. Теперь я более точно понимаю бутстрап и что нужно еще очень много понять и во многое вникнуть в теории и (надеюсь), что и на практике.

Вроде мы больше ничего не забыли разобрать, но просто для того, чтобы добить тему, я сделал тест Шапиро-Уилка на финальном дотасете, на котором мы применяем norm.cdf (где уже распределение разниц средних бустрапированных выборок). Вот результат: ShapiroResult(statistic=0.9976387023925781, pvalue=0.16199442744255066). Все же, распределение стат. значимо можно назвать нормальным, тк мы не сможем отклонить H0 о нормальности. =)